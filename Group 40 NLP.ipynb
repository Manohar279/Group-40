{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11480025,"sourceType":"datasetVersion","datasetId":7195142,"isSourceIdPinned":false},{"sourceId":11483178,"sourceType":"datasetVersion","datasetId":7197127},{"sourceId":11487873,"sourceType":"datasetVersion","datasetId":7200667}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"01b888d6d84145afbe11f55a81eb9a4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03b9517db5d846ac8eb6b06f1f5f9c3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a12ac57cf5c47bd88638b86fa7c359b","placeholder":"​","style":"IPY_MODEL_e3080373a4834803aaed1f5a44f9150d","value":" 456k/456k [00:00&lt;00:00, 8.66MB/s]"}},"0403ee1973ea4565b9a67f041ca3bb3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05bd7e14a45a43a89108640ff7b04d83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0403ee1973ea4565b9a67f041ca3bb3d","placeholder":"​","style":"IPY_MODEL_1e319ef284e849e5b8ad722b8adeddb7","value":" 499M/499M [00:06&lt;00:00, 40.6MB/s]"}},"0872a56ce01d4bf7be3e2c6a8c981424":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c40b78b0ada46d3ae2dae65a8924d5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54285884242b4de8bf95b795a3103068","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_633b871530c84f1d9b98ebf50c32cb59","value":481}},"0cd739fd3ff84a0f822f51311fe6e562":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1034ea0de4f842fa9b317aeed1ed8d13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0ebfa3a88074343a7bf44d161d2599c","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d65d09acb4494a29ae52f0c6e1047f8c","value":1355863}},"11e2bb746dcd444eb18c5c86c48eb8f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aa3c2da2a6643e98a4c5d5fbc411b7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f134021aa4dd46eda9116c8978fee102","IPY_MODEL_e0168488eedf42e989360715263515c1","IPY_MODEL_39bed60a63e44dafa2a08c94f1ade4c5"],"layout":"IPY_MODEL_bd8b9f8bd52141fcac4fefb6cf524a18"}},"1e319ef284e849e5b8ad722b8adeddb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2164b345a6fa40ceb9f965c643a20b7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f97d73d6140d406ca3c8e2c9824493f1","placeholder":"​","style":"IPY_MODEL_01b888d6d84145afbe11f55a81eb9a4e","value":"tokenizer.json: 100%"}},"21948e642c274b79bc6e635da7dfad95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"261f736f003f480ba386a84634c9b378":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96e2623e61c14b0b9ecffb23eb5543ac","placeholder":"​","style":"IPY_MODEL_21948e642c274b79bc6e635da7dfad95","value":" 1.36M/1.36M [00:00&lt;00:00, 16.0MB/s]"}},"2ccf4c047b194a80bbe56145ba105e21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3166a6100d754d9e8158f1eeacc4f30a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2164b345a6fa40ceb9f965c643a20b7a","IPY_MODEL_1034ea0de4f842fa9b317aeed1ed8d13","IPY_MODEL_261f736f003f480ba386a84634c9b378"],"layout":"IPY_MODEL_35cdcd513879402d9c197c703ed3b441"}},"33111171e21f442d8b2b6a31f2b27bbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33a2ca1258cd4e6fb782c4a411125e4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef289dbea9094889a0a17681ab973bea","IPY_MODEL_3d0382df0d684bc2bde90cd05503c58f","IPY_MODEL_03b9517db5d846ac8eb6b06f1f5f9c3d"],"layout":"IPY_MODEL_5999a79000a74b5c84cea7138a4a0727"}},"35cdcd513879402d9c197c703ed3b441":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39bed60a63e44dafa2a08c94f1ade4c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0872a56ce01d4bf7be3e2c6a8c981424","placeholder":"​","style":"IPY_MODEL_54ecf21563284e93958029a16e6d33e8","value":" 25.0/25.0 [00:00&lt;00:00, 1.64kB/s]"}},"3a0bdf4cd85d4690a7fbd4bfe1d6ee3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d0382df0d684bc2bde90cd05503c58f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e36357de5cd04bf9b13346bcfba8f652","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ccf4c047b194a80bbe56145ba105e21","value":456318}},"3d7dc5266d8b43d89a4c282ec3aac1b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ea1170ea9fc4132b99d3780509ef144":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41cc2c5a95cf4cf190a1841f5c52ca3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a0bdf4cd85d4690a7fbd4bfe1d6ee3b","placeholder":"​","style":"IPY_MODEL_716e5b375fe84a39b6481b6f28361df0","value":"vocab.json: 100%"}},"441160eed2df4a3cbeb4883ab516e3e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8361e2ee62d4cec9ad1d0f8350de189","placeholder":"​","style":"IPY_MODEL_dba32c898081440fbd343d606e0bc6af","value":" 481/481 [00:00&lt;00:00, 35.7kB/s]"}},"4ba2d1805d344494a1bc311684778ea5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50947dec6b474d309ffd26fc727e42d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ea1170ea9fc4132b99d3780509ef144","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ec2568688f5431dab0f6b130584b355","value":898823}},"54285884242b4de8bf95b795a3103068":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"543ed614656a4a3ebb629f03b622a4a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bebfbfab4e243719344b39c0afa31dc","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef4d7c6dd1874a48832c7e5af0ed6d37","value":498818054}},"54ecf21563284e93958029a16e6d33e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"565a6a3669c54ee48253bdfe016141e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5999a79000a74b5c84cea7138a4a0727":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a9cd301129d494590f51563f8c2e32a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"633b871530c84f1d9b98ebf50c32cb59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a8f76cfcf1445d7986f4ff672046400":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d05f18ac60104d21b8c4f7adac944c3e","placeholder":"​","style":"IPY_MODEL_3d7dc5266d8b43d89a4c282ec3aac1b4","value":" 899k/899k [00:00&lt;00:00, 10.3MB/s]"}},"6ec2568688f5431dab0f6b130584b355":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"716e5b375fe84a39b6481b6f28361df0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bebfbfab4e243719344b39c0afa31dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a12ac57cf5c47bd88638b86fa7c359b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c31aa7616e04259bdaa335924fc9c40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e2623e61c14b0b9ecffb23eb5543ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c505f6480a34009a4e638ef4a05b259":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a03023378a0f4bd68ee153840d37f943":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a679bc6eb6504616b6d101622ffabb9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd8b9f8bd52141fcac4fefb6cf524a18":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf0eeb530b5e4bf0bc21331085511d3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41cc2c5a95cf4cf190a1841f5c52ca3d","IPY_MODEL_50947dec6b474d309ffd26fc727e42d6","IPY_MODEL_6a8f76cfcf1445d7986f4ff672046400"],"layout":"IPY_MODEL_5a9cd301129d494590f51563f8c2e32a"}},"ca4282d342194c3bb0f1766cf361b344":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c31aa7616e04259bdaa335924fc9c40","placeholder":"​","style":"IPY_MODEL_565a6a3669c54ee48253bdfe016141e6","value":"model.safetensors: 100%"}},"d05f18ac60104d21b8c4f7adac944c3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d48c0a057fb84b9aa42ce29bc8aff393":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d65d09acb4494a29ae52f0c6e1047f8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dba32c898081440fbd343d606e0bc6af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0168488eedf42e989360715263515c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c505f6480a34009a4e638ef4a05b259","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e18c34fa8ef24a4a80581fd85cc811f0","value":25}},"e18328fb39a64a60a387645b0fd068c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e18c34fa8ef24a4a80581fd85cc811f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3080373a4834803aaed1f5a44f9150d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e36357de5cd04bf9b13346bcfba8f652":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4dc1a4665334db4a7fb0db34e33efd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e99a3a3a8d21476facf240c3d8c0fd52","IPY_MODEL_0c40b78b0ada46d3ae2dae65a8924d5a","IPY_MODEL_441160eed2df4a3cbeb4883ab516e3e3"],"layout":"IPY_MODEL_a679bc6eb6504616b6d101622ffabb9f"}},"e7c1c114faf24257b310e8924aae1bda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca4282d342194c3bb0f1766cf361b344","IPY_MODEL_543ed614656a4a3ebb629f03b622a4a8","IPY_MODEL_05bd7e14a45a43a89108640ff7b04d83"],"layout":"IPY_MODEL_11e2bb746dcd444eb18c5c86c48eb8f9"}},"e99a3a3a8d21476facf240c3d8c0fd52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ba2d1805d344494a1bc311684778ea5","placeholder":"​","style":"IPY_MODEL_e18328fb39a64a60a387645b0fd068c3","value":"config.json: 100%"}},"ef289dbea9094889a0a17681ab973bea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d48c0a057fb84b9aa42ce29bc8aff393","placeholder":"​","style":"IPY_MODEL_a03023378a0f4bd68ee153840d37f943","value":"merges.txt: 100%"}},"ef4d7c6dd1874a48832c7e5af0ed6d37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0ebfa3a88074343a7bf44d161d2599c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f134021aa4dd46eda9116c8978fee102":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33111171e21f442d8b2b6a31f2b27bbe","placeholder":"​","style":"IPY_MODEL_0cd739fd3ff84a0f822f51311fe6e562","value":"tokenizer_config.json: 100%"}},"f8361e2ee62d4cec9ad1d0f8350de189":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f97d73d6140d406ca3c8e2c9824493f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/declare-lab/RECCON.git","metadata":{"execution":{"iopub.status.busy":"2025-04-20T16:05:36.373403Z","iopub.execute_input":"2025-04-20T16:05:36.373565Z","iopub.status.idle":"2025-04-20T16:05:41.064873Z","shell.execute_reply.started":"2025-04-20T16:05:36.373549Z","shell.execute_reply":"2025-04-20T16:05:41.064044Z"},"id":"4XrmuYTwmvEi","outputId":"8c96587b-90c1-445a-9dca-db78e7ac4020","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nLoads a dialogue dataset from a JSON file, \nretains only the 'turn', 'speaker', and 'utterance' fields in each utterance, \nand writes the cleaned dialogue data to a new JSON file.\n\nSteps:\n1. Load the original dialogue JSON file.\n2. Traverse through the nested structure of conversation data.\n3. Remove any unwanted fields from each utterance.\n4. Save the cleaned data to 'clean_conversation.json'.\n\"\"\"\n\nimport json\n\n# Load JSON from a file\nwith open(\"/kaggle/working/RECCON/data/original_annotation/dailydialog_valid.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\n# Function to clean the data\ndef clean_json(data):\n    for key in data:  # Iterate over each conversation ID\n        for conversation in data[key]:  # Iterate over lists of utterances\n            for utterance in conversation:  # Iterate over individual utterances\n                keys_to_remove = [k for k in utterance if k not in {\"turn\", \"speaker\", \"utterance\"}]\n                for k in keys_to_remove:\n                    del utterance[k]\n\n# Clean the JSON structure\nclean_json(data)\n\n# Save cleaned JSON to a new file\nwith open(\"clean_conversation.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(data, f, indent=4)\n\nprint(\"Processing complete. Cleaned JSON saved t0 clean_conversation.json\")\n","metadata":{"execution":{"iopub.status.busy":"2025-04-20T16:06:21.029934Z","iopub.execute_input":"2025-04-20T16:06:21.030242Z","iopub.status.idle":"2025-04-20T16:06:21.041794Z","shell.execute_reply.started":"2025-04-20T16:06:21.030221Z","shell.execute_reply":"2025-04-20T16:06:21.041085Z"},"id":"4VIJuBRA-hyQ","outputId":"33eed2de-e86a-479b-ce6d-c5547bb3f384","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nThis script processes dialogue data in JSON format to extract meaningful clauses \nfrom utterances using spaCy's dependency parser. It then applies post-processing \nto merge certain clause patterns for better quality. The workflow includes:\n1. Clause extraction from each utterance.\n2. Removal of redundant or nested clauses.\n3. Merging of 'so'-starting and single-word clauses.\n4. Saving the processed output into a new JSON file.\n\"\"\"\n\n\n#Task 1\nimport re\nimport json\nimport spacy\n\n# Load the spaCy English model\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef clause_span(token, doc):\n    \"\"\"Return the surface‑ordered text span of token.subtree.\"\"\"\n    indices = sorted(t.i for t in token.subtree)\n    span = doc[indices[0] : indices[-1] + 1].text\n    return span\n\ndef extract_clauses(text):\n    \"\"\"\n    Extracts unique, non‑redundant clauses in surface order,\n    normalizing whitespace before punctuation.\n    \"\"\"\n    doc = nlp(text)\n    raw_clauses = []\n\n    # Select all predicate/subordinate clause heads\n    for token in doc:\n        if token.dep_ in {\"ROOT\", \"advcl\", \"ccomp\", \"acl\", \"xcomp\"}:\n            span = clause_span(token, doc)\n            # remove extra space before punctuation\n            span = re.sub(r'\\s+([,.;?!])', r'\\1', span).strip()\n            raw_clauses.append(span)\n\n    # Filter out any clause fully contained in a larger clause\n    clauses = []\n    for c in raw_clauses:\n        if not any(c != other and c in other for other in raw_clauses):\n            clauses.append(c)\n\n    return clauses\n\ndef process_conversations(input_file, output_file):\n    \"\"\"\n    Reads a JSON of conversations, extracts clauses for each utterance,\n    and writes the augmented data back to JSON.\n    \"\"\"\n    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n        conversations = json.load(f)\n\n    for conv_id, dialogues in conversations.items():\n        for dialogue in dialogues:\n            for turn in dialogue:\n                utt = turn.get(\"utterance\", \"\")\n                turn[\"clauses\"] = extract_clauses(utt)\n\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(conversations, f, indent=4, ensure_ascii=False)\n\n    print(f\"Processed data saved to {output_file}\")\n\nif __name__ == \"__main__\":\n    # Adjust these paths as needed\n    input_file = \"/kaggle/working/RECCON/data/original_annotation/dailydialog_train.json\"\n    output_file = \"extracted_clauses_corrected_train.json\"\n    process_conversations(input_file, output_file)\n\n\nimport json\n\ndef remerge_so_and_single_clauses(clauses):\n    \"\"\"\n    Given a list of clause strings, performs two kinds of merging:\n    1. Any clause starting with 'so ' (case-insensitive) is merged into the previous clause.\n    2. Any single-word clause is merged into the following clause.\n    Returns a new list of merged clauses.\n    \"\"\"\n    # Step 1: merge 'so ' clauses into the previous one\n    merged = []\n    for clause in clauses:\n        stripped = clause.lstrip()\n        if merged and stripped.lower().startswith(\"so \"):\n            prev = merged[-1].rstrip(\" .?!\")\n            # capitalize first word of the 'so' clause and append\n            merged[-1] = prev + \" \" + stripped.capitalize()\n        else:\n            merged.append(clause)\n\n    # Step 2: merge single-word clauses into the next one\n    final = []\n    i = 0\n    while i < len(merged):\n        clause = merged[i].strip()\n        # count words ignoring punctuation\n        word_only = clause.strip(\".?!\")\n        if i + 1 < len(merged) and len(word_only.split()) == 1:\n            # merge this single word with the next clause\n            next_clause = merged[i + 1].lstrip()\n            # lowercase first character of next clause for smooth merging\n            if next_clause:\n                merged_next = word_only + \" \" + next_clause[0].lower() + next_clause[1:]\n            else:\n                merged_next = word_only\n            final.append(merged_next)\n            i += 2  # skip the next clause since we've merged it\n        else:\n            final.append(merged[i])\n            i += 1\n\n    return final\n\n\ndef postprocess_file(input_file, output_file):\n    \"\"\"\n    Loads a JSON of conversations (with a 'clauses' list per turn),\n    applies remerge_so_and_single_clauses to each turn, and writes out the result.\n    \"\"\"\n    with open(input_file, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n\n    for conv_id, dialogues in data.items():\n        for dialogue in dialogues:\n            for turn in dialogue:\n                if 'clauses' in turn and isinstance(turn['clauses'], list):\n                    turn['clauses'] = remerge_so_and_single_clauses(turn['clauses'])\n\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(data, f, indent=4, ensure_ascii=False)\n\n    print(f\"Post-processed data saved to {output_file}\")\n\nif __name__ == \"__main__\":\n    postprocess_file(\n        \"extracted_clauses_corrected_train.json\",\n        \"extracted_clauses_train.json\"\n    )\n","metadata":{"id":"VvG1kuEjZ5h6","outputId":"893b72d6-7ff3-46a2-cfcc-1d5bff3704bc","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:17:58.233211Z","iopub.execute_input":"2025-04-20T16:17:58.233922Z","iopub.status.idle":"2025-04-20T16:18:44.662819Z","shell.execute_reply.started":"2025-04-20T16:17:58.233897Z","shell.execute_reply":"2025-04-20T16:18:44.662208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nThis program extracts clause-level emotion and cause labels from annotated dialogues.\n\nSteps:\n1. Load the input JSON file containing dialogue turns with emotion and cause annotations.\n2. Extract all emotion cause spans for each dialogue.\n3. For each clause in a turn, check if it expresses emotion, cause, both, or neither.\n4. Assign labels accordingly and write the result to a CSV file with columns:\n   clause_text, emotion_label, clause_label.\n\"\"\"\n\n\nimport json\nimport csv\n\ndef build_clause_dataset(input_json, output_csv):\n    with open(input_json, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n\n    with open(output_csv, 'w', newline='', encoding='utf-8') as fout:\n        writer = csv.writer(fout)\n        writer.writerow([\"clause_text\", \"emotion_label\", \"clause_label\"])\n\n        for conv in data.values():\n            for dialogue in conv:\n                # Step 1: gather all cause spans from the dialogue\n                all_cause_spans = []\n                for turn in dialogue:\n                    spans = turn.get(\"expanded emotion cause span\", [])\n                    all_cause_spans.extend([span.strip() for span in spans])\n\n                # Step 2: now process each clause in context of all cause spans\n                for turn in dialogue:\n                    emotion_label = turn.get(\"emotion\", \"neutral\")\n                    clauses = turn.get(\"clauses\", [])\n\n                    for clause in clauses:\n                        is_emotion = emotion_label != \"neutral\"\n                        is_cause = any(span in clause for span in all_cause_spans)\n\n                        if is_emotion and is_cause:\n                            clause_label = \"both\"\n                        elif is_emotion:\n                            clause_label = \"emotion\"\n                        elif is_cause:\n                            clause_label = \"cause\"\n                        else:\n                            clause_label = \"neither\"\n\n                        writer.writerow([clause, emotion_label,clause_label])\n\n    print(f\"✅ Dataset written to {output_csv}\")\n\nif __name__ == \"__main__\":\n    build_clause_dataset(\n        \"extracted_clauses_test.json\",\n        \"clause_dataset_test.csv\"\n    )\n","metadata":{"id":"NpKvtcUgf_dY","outputId":"355d2cfd-fb5e-44eb-be18-63661c28deac","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:31:50.422718Z","iopub.execute_input":"2025-04-20T16:31:50.423043Z","iopub.status.idle":"2025-04-20T16:31:50.453010Z","shell.execute_reply.started":"2025-04-20T16:31:50.423022Z","shell.execute_reply":"2025-04-20T16:31:50.452384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nThis program generates clause-level embeddings for a train-test dataset using the RoBERTa model.\nEach clause is associated with an emotion label, and the embeddings are stored in a PyTorch .pt file.\n\nSteps:\n1. Load a JSON file containing dialogues and clause-level annotations.\n2. Use the RoBERTa transformer to compute embeddings for each clause.\n3. Associate each clause with its corresponding emotion label.\n4. Organize data per conversation ID and save embeddings, clauses, and emotion labels as a dictionary to a .pt file.\n\"\"\"\n\nimport json\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom tqdm import tqdm\n\n# Setup\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\nmodel = AutoModel.from_pretrained(\"roberta-base\")\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Load clauses\nwith open(\"/kaggle/working/extracted_clauses_train.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\n# Clause embeddings: {conv_id: {\"clauses\": [...], \"embeddings\": Tensor [n,768], \"emotions\": [...]}}\nclause_data = {}\n\ndef embed_clause(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    return outputs.last_hidden_state[:, 0, :].squeeze(0).cpu()  # [768]\n\n# Process each conversation\nfor conv_id, dialogue in tqdm(data.items(), desc=\"Embedding clauses\"):\n    all_clauses = []\n    all_embeddings = []\n    all_emotions = []\n\n    for turn in dialogue:\n        for utt in turn:\n            emotion = utt.get(\"emotion\", \"neutral\")\n            clauses = utt.get(\"clauses\", [])\n            for clause in clauses:\n                emb = embed_clause(clause)\n                all_clauses.append(clause)\n                all_embeddings.append(emb)\n                all_emotions.append(emotion)  # associate this clause with its turn's emotion\n\n    if all_embeddings:\n        clause_data[conv_id] = {\n            \"clauses\": all_clauses,\n            \"embeddings\": torch.stack(all_embeddings),  # shape: [num_clauses, 768]\n            \"emotions\": all_emotions                    # shape: [num_clauses]\n        }\n\n# Save to .pt file\ntorch.save(clause_data, \"clause_embeddings_with_emotions_train.pt\")\nprint(\"✅ Saved clause embeddings and emotion labels to clause_embeddings_with_emotions file\")\n","metadata":{"id":"aUymIkChGkIp","outputId":"ee02abac-66ae-4c69-bf93-0a226fbb569e","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:23:35.315406Z","iopub.execute_input":"2025-04-20T16:23:35.316346Z","iopub.status.idle":"2025-04-20T16:25:07.075252Z","shell.execute_reply.started":"2025-04-20T16:23:35.316320Z","shell.execute_reply":"2025-04-20T16:25:07.074501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nThis script extracts pairs of emotion and cause clauses from a given JSON file of dialogues.\nIt then labels these pairs as positive or negative based on the relationship between the emotion and cause clauses.\n\nSteps:\n1. Load the input JSON file containing dialogues.\n2. Flatten the clauses for each dialogue and collect emotion and cause spans.\n3. For each emotion clause, find its corresponding cause clause and create positive pairs.\n4. For each positive pair, sample one negative pair that does not have an emotion-cause relationship.\n5. Label the pairs (positive: 1, negative: 0) and add their relationship type (if any).\n6. Save the generated pairs to an output JSON file and print the pair counts.\n\nThe output contains a dictionary with conversation IDs as keys and a list of clause pairs with their attributes.\nEach pair has:\n- \"emotion_idx\": Index of the emotion clause\n- \"cause_idx\": Index of the cause clause\n- \"label\": 1 for positive pairs, 0 for negative pairs\n- \"type\": Relationship type (e.g., \"no-context\")\n\"\"\"\n\n\nimport json\nimport random\n\ndef extract_clause_pairs_with_types(input_json, output_json):\n    with open(input_json, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n\n    output = {}\n    pair_type_counts = {\"positive\": 0, \"negative\": 0}  # To count types\n\n    for conv_id, dialogue in data.items():\n        flat_clauses = []\n        emotion_clause_idxs = set()\n        cause_clause_idxs = set()\n        gold_pairs = set()\n        pair_types = {}\n\n        # Step 1: Flatten all clauses\n        clause_idx = 0\n        turn_clause_ranges = []\n        for turn in dialogue:\n            for utt in turn:\n                num_clauses = len(utt.get(\"clauses\", []))\n                turn_clause_ranges.append((utt, clause_idx, clause_idx + num_clauses))\n                clause_idx += num_clauses\n\n        flat_clauses = [clause for turn in dialogue for utt in turn for clause in utt.get(\"clauses\", [])]\n\n        if len(flat_clauses) == 0:\n            continue  # skip conversations with no clauses\n\n        # Step 2: Find emotion and cause clauses, and collect gold pairs\n        for utt, start_idx, end_idx in turn_clause_ranges:\n            emotion = utt.get(\"emotion\", \"neutral\")\n            type_ = utt.get(\"type\", [\"no-context\"])[0]\n            cause_spans = [s.strip() for s in utt.get(\"expanded emotion cause span\", [])]\n\n            if emotion != \"neutral\":\n                for i in range(start_idx, end_idx):\n                    emotion_clause_idxs.add(i)\n\n            for span in cause_spans:\n                for j in range(len(flat_clauses)):\n                    if span in flat_clauses[j]:\n                        cause_clause_idxs.add(j)\n                        for i in range(start_idx, end_idx):\n                            if emotion != \"neutral\":\n                                gold_pairs.add((i, j))\n                                pair_types[(i, j)] = type_\n\n        # Step 3: Construct final pairs with 1 negative sample per positive\n        final_pairs = []\n        for i in emotion_clause_idxs:\n            positives = [j for j in range(len(flat_clauses)) if (i, j) in gold_pairs]\n            negatives = [j for j in range(len(flat_clauses)) if (i, j) not in gold_pairs and j != i]\n\n            for j in positives:\n                rel_type = pair_types.get((i, j), \"no-context\")\n                final_pairs.append({\n                    \"emotion_idx\": i,\n                    \"cause_idx\": j,\n                    \"label\": 1,\n                    \"type\": rel_type\n                })\n\n                # Increment count for positive pair\n                pair_type_counts[\"positive\"] += 1\n\n                # Sampling 1 negative pair for each positive pair\n                if negatives:\n                    neg_samples = random.sample(negatives, k=min(random.choice([0, 1]), len(negatives)))\n                    for neg_j in neg_samples:\n                        final_pairs.append({\n                            \"emotion_idx\": i,\n                            \"cause_idx\": neg_j,\n                            \"label\": 0,\n                            \"type\": \"no-context\"\n                        })\n                         # Increment count for negative pair\n                        pair_type_counts[\"negative\"] += 1\n\n        if final_pairs:\n            output[conv_id] = final_pairs\n\n    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n        json.dump(output, f, indent=2)\n    print(f\"✅ Saved labeled clause pairs with types to {output_json}\")\n\n    # Print the pair counts\n    print(\"Pair counts:\")\n    print(f\"Positive pairs: {pair_type_counts['positive']}\")\n    print(f\"Negative pairs: {pair_type_counts['negative']}\")\n\n# Example usage\nif __name__ == \"__main__\":\n    extract_clause_pairs_with_types(\n        \"/kaggle/working/extracted_clauses_train.json\",\n        \"clause_pair_labels_with_cause_type_train.json\"\n    )\n","metadata":{"execution":{"iopub.status.busy":"2025-04-20T16:28:08.211200Z","iopub.execute_input":"2025-04-20T16:28:08.211497Z","iopub.status.idle":"2025-04-20T16:28:08.341351Z","shell.execute_reply.started":"2025-04-20T16:28:08.211477Z","shell.execute_reply":"2025-04-20T16:28:08.340705Z"},"id":"gpL_A0x5vOJX","outputId":"f757cf51-a1c4-415e-8a5d-cdacdc0f9457","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nThis script processes a dataset containing emotional labels for text clauses and consolidates synonyms into a single label to reduce label sparsity.\n\nSteps:\n1. Load the dataset from a CSV file.\n2. Compute the support (frequency) of each label in the 'emotion_label' column.\n3. Define semantic groups of synonyms (e.g., 'angry' and 'anger' are treated as the same).\n4. Build a mapping from lower-support synonyms to the higher-support representative label within each semantic group.\n5. Replace all occurrences of synonyms with the corresponding higher-support label.\n6. Save the cleaned dataset into a new CSV file.\n7. Optionally, print out the label replacements that occurred.\n\nThe goal is to make the dataset less sparse and more consistent by consolidating similar emotion labels into one representative label.\n\"\"\"\n\n\nimport pandas as pd\nfrom collections import defaultdict\n\n# Load your CSV\ndf = pd.read_csv(\"/kaggle/working/clause_dataset_test.csv\")\n\n# Assume the label column is named 'label'\nlabel_col = 'emotion_label'\n\n# Step 1: Compute label support\nsupport = df[label_col].value_counts().to_dict()\n\n# Step 2: Define semantic equivalents\nsemantic_groups = [\n    ['anger', 'angry'],\n    ['happiness', 'happy', 'excited'],\n    ['surprise', 'surprised'],\n    ['disgust'],\n    ['fear'],\n    ['sadness'],\n    ['neutral']\n]\n\n# Step 3: Build mapping from lower-support synonyms to higher-support one\nreplacement_map = {}\nfor group in semantic_groups:\n    # Get support values for all in group\n    group_supports = {label: support.get(label, 0) for label in group}\n    # Find the label with max support\n    target_label = max(group_supports, key=group_supports.get)\n    # Map other labels to this one\n    for label in group:\n        if label != target_label:\n            replacement_map[label] = target_label\n\n# Step 4: Replace labels\ndf[label_col] = df[label_col].replace(replacement_map)\n\n# Step 5: Save cleaned CSV\ndf.to_csv(\"clause_dataset_test.csv\", index=False)\n\n# Optional: print what was replaced\nprint(\"Replaced labels:\")\nfor old, new in replacement_map.items():\n    print(f\"{old} → {new}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-04-20T16:32:05.326861Z","iopub.execute_input":"2025-04-20T16:32:05.327163Z","iopub.status.idle":"2025-04-20T16:32:05.352042Z","shell.execute_reply.started":"2025-04-20T16:32:05.327143Z","shell.execute_reply":"2025-04-20T16:32:05.351428Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nThis script is designed for training a multi-class classification model \nto predict emotions and clauses from text using a transformer-based \napproach. The code uses pre-trained models (RoBERTa for emotion classification \nand BERT for clause classification) and fine-tunes them on custom datasets.\n\nThe script performs the following steps:\n1. Data Preprocessing: Loads and preprocesses emotion and clause datasets, \n   including fixing typos, label encoding, and saving the encoders.\n2. Class Weight Calculation**: Computes class weights to handle class imbalance \n   for the clause classification task.\n3. Tokenizer Initialization: Loads tokenizers for both emotion and clause models.\n4. Dataset Creation: Creates custom dataset classes for both emotion and clause tasks.\n5. Weighted Sampling: Implements weighted random samplers to address class imbalance \n   during training.\n6. Model Definition: Defines transformer-based models for both emotion and clause classification, \n   using BERT-like architectures with a linear classifier head.\n7. Loss Functions: Implements Focal Loss for clause classification to improve performance \n   on imbalanced classes, and Cross-Entropy Loss for emotion classification.\n8. Training Loop: Defines the training loop, which optimizes the models using AdamW \n   and uses a learning rate scheduler to adjust the learning rate based on performance.\n9. Model Evaluation: Evaluates the models on test datasets and generates classification reports.\n\nKey components:\n- Emotion classification with RoBERTa (Twitter model)\n- Clause classification with BERT (base model)\n- Handling class imbalance using weighted random sampling and loss functions\n- Saving the tokenizers and label encoders for future use\n'''\n\n\n\n# Task 2\nimport os\n# Make CUDA errors synchronous for accurate tracebacks\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nimport pickle\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom tqdm import tqdm\nimport numpy as np\nimport joblib\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Config\nMODEL_NAME_EMOTION = 'cardiffnlp/twitter-roberta-base-emotion'\nMODEL_NAME_CLAUSE  = 'bert-base-uncased'\nMAX_LEN    = 128\nBATCH_SIZE = 16\nEPOCHS     = 12\nLR         = 1e-5\nWD         = 0.01\nPATIENCE   = 3\n\n# Paths\nTRAIN_CSV = '/kaggle/working/clause_dataset_train.csv'\nTEST_CSV  = '/kaggle/working/clause_dataset_test.csv'\n\n# Load & preprocess\ndf_train = pd.read_csv(TRAIN_CSV)\ndf_test  = pd.read_csv(TEST_CSV)\n\n# Fix typos\nfix_map = {\"happines\": \"happiness\", \"sad\": \"sadness\"}\ndf_train['emotion_label'] = df_train['emotion_label'].replace(fix_map)\ndf_test ['emotion_label'] = df_test ['emotion_label'].replace(fix_map)\n\n# Encode labels\nemotion_encoder = LabelEncoder()\nclause_encoder  = LabelEncoder()\nemotion_encoder.fit(df_train['emotion_label'].tolist() + df_test['emotion_label'].tolist())\nclause_encoder .fit(df_train['clause_label'].tolist()  + df_test['clause_label'].tolist())\n\nfor df in (df_train, df_test):\n    df['emotion_label_enc'] = emotion_encoder.transform(df['emotion_label'])\n    df['clause_label_enc']  = clause_encoder.transform(df['clause_label'])\n\n# Save encoders\nwith open('encoder_emotion.pkl', 'wb') as f:\n    pickle.dump(emotion_encoder, f)\nwith open('encoder_clause.pkl', 'wb') as f:\n    pickle.dump(clause_encoder, f)\n    \n# Compute class weights for clause loss\nnum_clause_classes = len(clause_encoder.classes_)\npresent = np.unique(df_train['clause_label_enc'])\nw_present = compute_class_weight(class_weight='balanced',\n                                 classes=present,\n                                 y=df_train['clause_label_enc'])\nclause_weights = np.zeros(num_clause_classes, dtype=np.float32)\nfor cls, w in zip(present, w_present):\n    clause_weights[int(cls)] = w\nclause_weights_tensor = torch.tensor(clause_weights, dtype=torch.float)\n\n# Tokenizers\n\ntokenizer_emotion = AutoTokenizer.from_pretrained(MODEL_NAME_EMOTION)\nwith open('tokenizer_emotion.pkl', 'wb') as f:\n    pickle.dump(tokenizer_emotion, f)\ntokenizer_clause  = AutoTokenizer.from_pretrained(MODEL_NAME_CLAUSE)\nwith open('tokenizer_clause.pkl', 'wb') as f:\n    pickle.dump(tokenizer_clause, f)\n\nnp.save('emotion_label_classes.npy', emotion_encoder.classes_)\nnp.save('clause_label_classes.npy',  clause_encoder.classes_)\n\n# Dataset definition\nTEXT_COL = 'clause_text'\nclass ClauseDataset(Dataset):\n    def __init__(self, df, tokenizer):\n        self.texts = df[TEXT_COL].tolist()\n        self.em_ls = df['emotion_label_enc'].tolist()\n        self.cl_ls = df['clause_label_enc'].tolist()\n        self.tok   = tokenizer\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        enc = self.tok(self.texts[idx],\n                       truncation=True,\n                       padding='max_length',\n                       max_length=MAX_LEN,\n                       return_tensors='pt')\n        return {\n            'input_ids':      enc['input_ids'].squeeze(0),\n            'attention_mask': enc['attention_mask'].squeeze(0),\n            'emotion_label':  torch.tensor(self.em_ls[idx], dtype=torch.long),\n            'clause_label':   torch.tensor(self.cl_ls[idx], dtype=torch.long)\n        }\n\n# Samplers for oversampling\ne_counts = df_train['emotion_label_enc'].value_counts().sort_index().values\nw_em     = 1.0 / e_counts\nsampler_em = WeightedRandomSampler(w_em[df_train['emotion_label_enc']],\n                                   num_samples=len(df_train), replacement=True)\n\nc_counts = df_train['clause_label_enc'].value_counts().reindex(\n    np.arange(num_clause_classes), fill_value=0).values\nw_cl     = 1.0 / (c_counts + 1e-6)\nsampler_cl = WeightedRandomSampler(w_cl[df_train['clause_label_enc']],\n                                   num_samples=len(df_train), replacement=True)\n\n# Dataloaders\nds_tr_em = ClauseDataset(df_train, tokenizer_emotion)\nds_te_em = ClauseDataset(df_test,  tokenizer_emotion)\ntrain_loader_em = DataLoader(ds_tr_em, batch_size=BATCH_SIZE, sampler=sampler_em)\ntest_loader_em  = DataLoader(ds_te_em, batch_size=BATCH_SIZE)\n\nds_tr_cl = ClauseDataset(df_train, tokenizer_clause)\nds_te_cl = ClauseDataset(df_test,  tokenizer_clause)\ntrain_loader_cl = DataLoader(ds_tr_cl, batch_size=BATCH_SIZE, sampler=sampler_cl)\ntest_loader_cl  = DataLoader(ds_te_cl,  batch_size=BATCH_SIZE)\n\n# Loss & Models\nclass FocalLoss(nn.Module):\n    def __init__(self, weights=None, gamma=2.0):\n        super().__init__()\n        self.gamma = gamma\n        self.register_buffer('weights', weights)\n        self.ce = nn.CrossEntropyLoss(weight=weights, reduction='none')\n    def forward(self, logits, targets):\n        ce = self.ce(logits, targets)\n        pt = torch.exp(-ce)\n        return ((1 - pt)**self.gamma * ce).mean()\n\nclass EmotionModel(nn.Module):\n    def __init__(self, num_labels):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(MODEL_NAME_EMOTION)\n        hid = self.bert.config.hidden_size\n        self.dropout = nn.Dropout(0.4)\n        self.norm    = nn.LayerNorm(hid)\n        self.classifier = nn.Linear(hid, num_labels)\n    def forward(self, input_ids, attention_mask):\n        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = self.norm(self.dropout(out.last_hidden_state[:,0,:]))\n        return self.classifier(pooled)\n\nclass ClauseModel(nn.Module):\n    def __init__(self, num_labels):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(MODEL_NAME_CLAUSE)\n        hid = self.bert.config.hidden_size\n        self.dropout = nn.Dropout(0.4)\n        self.norm    = nn.LayerNorm(hid)\n        self.classifier = nn.Linear(hid, num_labels)\n    def forward(self, input_ids, attention_mask):\n        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = self.norm(self.dropout(out.last_hidden_state[:,0,:]))\n        return self.classifier(pooled)\n\nemotion_model = EmotionModel(len(emotion_encoder.classes_)).to(device)\nclause_model  = ClauseModel(len(clause_encoder.classes_)).to(device)\ncrit_em = nn.CrossEntropyLoss()\ncrit_cl = FocalLoss(weights=clause_weights_tensor).to(device)\n\noptim_em = AdamW(emotion_model.parameters(), lr=LR, weight_decay=WD)\noptim_cl = AdamW(clause_model.parameters(),  lr=LR, weight_decay=WD)\nsched    = ReduceLROnPlateau(optim_em, mode='min', patience=2, factor=0.5, verbose=True)\n\n# (Training and evaluation loops remain the same as earlier provided)\n# ── Training & Evaluation ─────────────────────────────────────────────────────\ndef train_epoch_emotion():\n    emotion_model.train()\n    total_loss, correct, total = 0, 0, 0\n    for b in tqdm(train_loader_em, desc='Train Emotion'):\n        ids, attn, y = (b['input_ids'].to(device),\n                        b['attention_mask'].to(device),\n                        b['emotion_label'].to(device))\n        optim_em.zero_grad()\n        logits = emotion_model(ids, attn)\n        loss   = crit_em(logits, y)\n        loss.backward()\n        nn.utils.clip_grad_norm_(emotion_model.parameters(), 1.0)\n        optim_em.step()\n        total_loss += loss.item()\n        correct    += (logits.argmax(1)==y).sum().item()\n        total      += y.size(0)\n    return total_loss/len(train_loader_em), correct/total\n\n@torch.no_grad()\ndef evaluate_emotion():\n    emotion_model.eval()\n    all_y, all_p = [], []\n    total_loss = correct = total = 0\n    for b in tqdm(test_loader_em, desc='Eval Emotion'):\n        ids = b['input_ids'].to(device)\n        attn = b['attention_mask'].to(device)\n        y = b['emotion_label'].to(device)\n\n        logits = emotion_model(ids, attn)\n        loss = crit_em(logits, y)\n        total_loss += loss.item()\n\n        pred = logits.argmax(1)\n        correct += (pred == y).sum().item()\n        total += y.size(0)\n\n        all_y.extend(y.cpu().tolist())\n        all_p.extend(pred.cpu().tolist())\n\n    rpt = classification_report(\n        all_y,\n        all_p,\n        labels=list(range(len(emotion_encoder.classes_))),\n        target_names=emotion_encoder.classes_,\n        zero_division=0\n    )\n    return total_loss / len(test_loader_em), correct / total, rpt\n\ndef train_epoch_clause():\n    clause_model.train()\n    total_loss, correct, total = 0, 0, 0\n    for b in tqdm(train_loader_cl, desc='Train Clause'):\n        ids, attn, y = (b['input_ids'].to(device),\n                        b['attention_mask'].to(device),\n                        b['clause_label'].to(device))\n        optim_cl.zero_grad()\n        logits = clause_model(ids, attn)\n        loss   = crit_cl(logits, y)\n        loss.backward()\n        nn.utils.clip_grad_norm_(clause_model.parameters(), 1.0)\n        optim_cl.step()\n        total_loss += loss.item()\n        correct    += (logits.argmax(1)==y).sum().item()\n        total      += y.size(0)\n    return total_loss/len(train_loader_cl), correct/total\n\n@torch.no_grad()\ndef evaluate_clause():\n    clause_model.eval()\n    all_y, all_p = [], []\n    total_loss = correct = total = 0\n    for b in tqdm(test_loader_cl, desc='Eval Clause'):\n        ids = b['input_ids'].to(device)\n        attn = b['attention_mask'].to(device)\n        y = b['clause_label'].to(device)\n\n        logits = clause_model(ids, attn)\n        loss = crit_cl(logits, y)\n        total_loss += loss.item()\n\n        pred = logits.argmax(1)\n        correct += (pred == y).sum().item()\n        total += y.size(0)\n\n        all_y.extend(y.cpu().tolist())\n        all_p.extend(pred.cpu().tolist())\n\n    rpt = classification_report(\n        all_y,\n        all_p,\n        labels=list(range(len(clause_encoder.classes_))),\n        target_names=clause_encoder.classes_,\n        zero_division=0\n    )\n    return total_loss / len(test_loader_cl), correct / total, rpt\n\n# ── Main Loop ──────────────────────────────────────────────────────────────────\nbest_em_acc, best_cl_acc, no_imp = 0.0, 0.0, 0\nfor ep in range(1, EPOCHS+1):\n    print(f\"\\n── Epoch {ep}/{EPOCHS} ─────────────────────────\")\n    tr_em_loss, tr_em_acc = train_epoch_emotion()\n    tr_cl_loss, tr_cl_acc = train_epoch_clause()\n    val_em_loss, val_em_acc, rpt_em = evaluate_emotion()\n    val_cl_loss, val_cl_acc, rpt_cl = evaluate_clause()\n    sched.step(val_em_loss)\n\n    print(f\"Emotion | train_loss={tr_em_loss:.4f} acc={tr_em_acc:.4f} | \"\n          f\"val_loss={val_em_loss:.4f} acc={val_em_acc:.4f}\")\n    print(\"Emotion classification report:\\n\", rpt_em)\n    print(f\"Clause  | train_loss={tr_cl_loss:.4f} acc={tr_cl_acc:.4f} | \"\n          f\"val_loss={val_cl_loss:.4f} acc={val_cl_acc:.4f}\")\n    print(\"Clause classification report:\\n\", rpt_cl)\n\n    # early stopping & save\n    if val_em_acc > best_em_acc or val_cl_acc > best_cl_acc:\n        best_em_acc = max(best_em_acc, val_em_acc)\n        best_cl_acc = max(best_cl_acc, val_cl_acc)\n        no_imp = 0\n        torch.save(emotion_model.state_dict(), 'best_emotion_model.pt')\n        torch.save(clause_model.state_dict(),  'best_clause_model.pt')\n        print(\"✅ Models improved and saved.\")\n    else:\n        no_imp += 1\n        print(f\"⚠️ No improvement ({no_imp}/{PATIENCE})\")\n        if no_imp >= PATIENCE:\n            print(\"⏹️ Early stopping triggered.\")\n            break\n\n# ── Final Evaluation ─────────────────────────────────────────────────────────\nprint(\"\\n📊 Final evaluation with best checkpoints:\")\nemotion_model.load_state_dict(torch.load('best_emotion_model.pt', map_location=device))\nclause_model .load_state_dict(torch.load('best_clause_model.pt',  map_location=device))\n\n_, fe_acc, fe_rpt = evaluate_emotion()\n_, fc_acc, fc_rpt = evaluate_clause()\nprint(f\"Final Emotion Acc: {fe_acc:.4f}\\n\", fe_rpt)\nprint(f\"Final Clause  Acc: {fc_acc:.4f}\\n\", fc_rpt)","metadata":{"execution":{"iopub.status.busy":"2025-04-20T16:56:24.773353Z","iopub.execute_input":"2025-04-20T16:56:24.774106Z","iopub.status.idle":"2025-04-20T18:14:21.920691Z","shell.execute_reply.started":"2025-04-20T16:56:24.774080Z","shell.execute_reply":"2025-04-20T18:14:21.919906Z"},"id":"WLusXhIfcGHK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch-geometric -q","metadata":{"execution":{"iopub.execute_input":"2025-04-20T11:11:33.532792Z","iopub.status.busy":"2025-04-20T11:11:33.532601Z","iopub.status.idle":"2025-04-20T11:11:38.659117Z","shell.execute_reply":"2025-04-20T11:11:38.658428Z","shell.execute_reply.started":"2025-04-20T11:11:33.532775Z"},"id":"57Iphb9r9hHA","outputId":"06234bf5-23b0-4c8c-825c-e4bc1dfc3fa4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nThe code is for training a binary classification model to predict emotion-cause \nrelationships between clause pairs using a Graph Attention Network (GAT). It builds \na graph from conversation clause embeddings and annotated links, and trains the model \nusing focal loss to handle class imbalance effectively.\n\nThe code follows these steps:\n1. Data loading and conversion of clause-pair annotations into graph structures.\n2. Definition of the GAT-based link prediction model.\n3. Training loop with Focal Loss, evaluation using accuracy and classification report.\n4. Early stopping based on validation performance and saving the best model.\n'''\n\n\n# Task 3\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GATConv\nimport json\nfrom sklearn.metrics import classification_report, accuracy_score\nimport os\n\n# ==================== Hyperparameters ====================\nBATCH_SIZE = 8\nHIDDEN = 48\nEPOCHS = 50\nPATIENCE = 8\nMODEL_OUT = \"best_gat_model.pt\"\nMODEL_FULL = \"best_gat_model_full.pt\"\n\n# ==================== Data Loading ====================\nTRAIN_CLAUSE_F = \"/kaggle/input/g40-007/clause_embeddings_with_emotions_train.pt\"\nTEST_CLAUSE_F = \"/kaggle/input/g40-007/clause_embeddings_with_emotions_test.pt\"\nTRAIN_PAIR_F = \"/kaggle/working/clause_pair_labels_with_types_train.json\"\nTEST_PAIR_F = \"/kaggle/working/clause_pair_labels_with_types_test.json\"\n\ndef build_data(conv_id, clause_data, pair_data):\n    info = clause_data[conv_id]\n    emb  = info[\"embeddings\"]    # [n_clauses, emb_dim]\n\n    # Get exactly the annotated pairs (they already include label=0 or 1)\n    pairs = pair_data.get(conv_id, [])\n    edge_list  = [(p[\"emotion_idx\"], p[\"cause_idx\"]) for p in pairs]\n    edge_label = [p[\"label\"]                for p in pairs]\n\n    # Convert to tensors\n    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()  # [2, E]\n    edge_label = torch.tensor(edge_label, dtype=torch.float)                 # [E]\n\n    return Data(x=emb, edge_index=edge_index, y_link=edge_label)\n\n\ndef build_dataset(clause_data, pair_data):\n    return [build_data(cid, clause_data, pair_data) for cid in clause_data if len(pair_data.get(cid, [])) > 0]\n    \nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.0, alpha=1.0, reduction='mean'):\n        super().__init__()\n        self.gamma    = gamma\n        self.alpha    = alpha\n        self.reduction= reduction\n        self.bce      = nn.BCEWithLogitsLoss(reduction='none')\n\n    def forward(self, logits, targets):\n        # per‐sample BCE\n        bce_loss = self.bce(logits, targets)\n        # probabilities for the true class\n        p        = torch.sigmoid(logits)\n        p_t      = targets * p + (1 - targets) * (1 - p)\n        # focal modulator\n        modulator= (1 - p_t) ** self.gamma\n        loss     = self.alpha * modulator * bce_loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss\n\n# ==================== Model ====================\nclass GATLinkPredictor(nn.Module):\n    def __init__(self, in_channels, hidden_channels, dropout=0.0):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.gat1 = GATConv(in_channels, hidden_channels, heads=4,\n                            concat=True, dropout=dropout)\n        self.gat2 = GATConv(hidden_channels * 4, hidden_channels,\n                            heads=1, concat=True, dropout=dropout)\n        \n        self.lin  = nn.Linear(hidden_channels * 2, 1)\n        self.norm1 = nn.LayerNorm(hidden_channels * 4)\n        self.norm2 = nn.LayerNorm(hidden_channels)\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = F.relu(self.norm1(self.gat1(x, edge_index)))\n        x = self.dropout(x)\n        x = self.norm2(self.gat2(x, edge_index))\n         # in forward:\n        \n        row, col = edge_index\n        edge_feat = torch.cat([x[row], x[col]], dim=1)\n        edge_feat = self.dropout(edge_feat)\n        return self.lin(edge_feat).squeeze(1)\n\n\n# ==================== Evaluation ====================\ndef evaluate(model, loader):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            link_logits = model(batch)\n            preds = torch.sigmoid(link_logits) > 0.55\n            all_preds.extend(preds.cpu().tolist())\n            all_labels.extend(batch.y_link.cpu().tolist())\n\n    acc = accuracy_score(all_labels, all_preds)\n    report = classification_report(all_labels, all_preds, digits=4, zero_division=0)\n    return acc, report\n\n# ==================== Load and Prepare ====================\n\ntrain_clause_data = torch.load(TRAIN_CLAUSE_F,weights_only=True)\ntest_clause_data = torch.load(TEST_CLAUSE_F,weights_only=True)\n\nwith open(TRAIN_PAIR_F, \"r\") as f:\n    train_pair_data = json.load(f)\nwith open(TEST_PAIR_F, \"r\") as f:\n    test_pair_data = json.load(f)\n\ntrain_data = build_dataset(train_clause_data, train_pair_data)\ntest_data = build_dataset(test_clause_data, test_pair_data)\n\nprint(f\"✅ Loaded {len(train_data)} train examples, {len(test_data)} test examples\")\n\ntrain_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=1)\n\n# ==================== Train Loop ====================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = GATLinkPredictor(in_channels=train_data[0].x.size(1), hidden_channels=HIDDEN).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\ncriterion = FocalLoss(gamma= 1.0, alpha=3.0)  # you can tweak gamma/alpha\n\nbest_acc = 0.0\nno_improve = 0\n\nprint(\"🚀 Starting training...\")\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        link_logits = model(batch)\n        loss = criterion(link_logits, batch.y_link)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    acc, _ = evaluate(model, test_loader)\n    print(f\"Epoch {epoch:02d}  Loss: {total_loss/len(train_loader):.4f}  Test Acc: {acc:.4f}\")\n\n    if acc > best_acc:\n        best_acc = acc\n        no_improve = 0\n        torch.save(model.state_dict(), MODEL_OUT)\n        torch.save(model, MODEL_FULL)\n        print(f\"✅ Best model saved (acc={acc:.4f})\")\n    else:\n        no_improve += 1\n        if no_improve >= PATIENCE:\n            print(f\"⏹️ Early stopping triggered at epoch {epoch}\")\n            break\n\n# ==================== Final Evaluation ====================\nprint(\"\\n📊 Final Evaluation:\")\nmodel = torch.load(MODEL_FULL, weights_only=False).to(device)\nmodel.eval()\nacc, report = evaluate(model, test_loader)\nprint(f\"Accuracy: {acc:.4f}\\n\")\nprint(report)\n","metadata":{"execution":{"iopub.execute_input":"2025-04-20T13:58:40.987459Z","iopub.status.busy":"2025-04-20T13:58:40.986574Z","iopub.status.idle":"2025-04-20T13:58:58.902378Z","shell.execute_reply":"2025-04-20T13:58:58.901740Z","shell.execute_reply.started":"2025-04-20T13:58:40.987425Z"},"id":"i3-uAJLD9RNZ","outputId":"b6d14ff8-3a42-4161-95d7-0bc7f30356d3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n- Extracts clauses from conversations using spaCy's dependency parsing.\n- Uses pre-trained transformer models to classify each clause's emotion and type.\n- Applies a Graph Attention Network (GAT) to predict emotion-cause relationships between clauses.\n- Loads all necessary artifacts (tokenizers, models, encoders) and processes input JSON data.\n- Outputs labeled results including emotions, clause types, and cause-effect pairs to a JSON file.\n'''\n\n\nimport argparse\nimport json\nimport re\nimport spacy\nimport torch\nimport pickle\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, AutoModel\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GATConv\n\n\nclass GATLinkPredictor(nn.Module):\n    def __init__(self, in_channels, hidden_channels, dropout=0.0):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.gat1 = GATConv(in_channels, hidden_channels, heads=4,\n                            concat=True, dropout=dropout)\n        self.gat2 = GATConv(hidden_channels * 4, hidden_channels,\n                            heads=1, concat=True, dropout=dropout)\n        \n        self.lin  = nn.Linear(hidden_channels * 2, 1)\n        self.norm1 = nn.LayerNorm(hidden_channels * 4)\n        self.norm2 = nn.LayerNorm(hidden_channels)\n\n    def forward(self, feats, edge_index):\n        x = F.relu(self.norm1(self.gat1(feats, edge_index)))\n        x = self.dropout(x)\n        x = self.norm2(self.gat2(x, edge_index))\n\n        row, col = edge_index\n        edge_feat = torch.cat([x[row], x[col]], dim=1)\n        edge_feat = self.dropout(edge_feat)\n        return self.lin(edge_feat).squeeze(1)\n\n\ndef clause_span(token, doc):\n    indices = sorted(t.i for t in token.subtree)\n    span = doc[indices[0] : indices[-1] + 1].text\n    return span\n\n\ndef extract_clauses(text, nlp):\n    doc = nlp(text)\n    raw_clauses = []\n\n    for token in doc:\n        if token.dep_ in {\"ROOT\", \"advcl\", \"ccomp\", \"acl\", \"xcomp\"}:\n            span = clause_span(token, doc)\n            span = re.sub(r'\\s+([,.;?!])', r'\\1', span).strip()\n            raw_clauses.append(span)\n\n    clauses = []\n    for c in raw_clauses:\n        if not any(c != other and c in other for other in raw_clauses):\n            clauses.append(c)\n\n    return clauses\n\n\ndef remerge_so_and_single_clauses(clauses):\n    merged = []\n    for clause in clauses:\n        stripped = clause.lstrip()\n        if merged and stripped.lower().startswith(\"so \"):\n            prev = merged[-1].rstrip(\" .?!\")\n            merged[-1] = prev + \" \" + stripped.capitalize()\n        else:\n            merged.append(clause)\n\n    final = []\n    i = 0\n    while i < len(merged):\n        clause = merged[i].strip()\n        word_only = clause.strip(\".?!\")\n        if i + 1 < len(merged) and len(word_only.split()) == 1:\n            next_clause = merged[i + 1].lstrip()\n            if next_clause:\n                merged_next = word_only + \" \" + next_clause[0].lower() + next_clause[1:]\n            else:\n                merged_next = word_only\n            final.append(merged_next)\n            i += 2\n        else:\n            final.append(merged[i])\n            i += 1\n\n    return final\n\n\ndef build_graph(node_feats):\n    num = node_feats.size(0)\n    row = []\n    col = []\n    for i in range(num):\n        for j in range(num):\n            if i != j:\n                row.append(i)\n                col.append(j)\n    edge_index = torch.tensor([row, col], dtype=torch.long)\n    return edge_index\n\n\ndef inference_pipeline(conversation, \n                       tokenizer_emotion, tokenizer_clause,\n                       model_emotion, model_clause, gat_model, \n                       emotion_encoder, clause_encoder, type_decoder,\n                       device, nlp):\n    clauses = []\n    for turn in conversation:\n        text = turn.get('utterance', '')\n        cs = extract_clauses(text, nlp)\n        cs = remerge_so_and_single_clauses(cs)\n        clauses.extend(cs)\n\n    enc_em = tokenizer_emotion(clauses, padding=True, truncation=True, return_tensors='pt', max_length=128).to(device)\n    enc_cl = tokenizer_clause(clauses, padding=True, truncation=True, return_tensors='pt', max_length=128).to(device)\n\n    with torch.no_grad():\n        logits_em = model_emotion(enc_em['input_ids'], enc_em['attention_mask'])\n        logits_cl = model_clause(enc_cl['input_ids'], enc_cl['attention_mask'])\n        feats = model_clause.bert(**enc_cl).last_hidden_state[:, 0, :]\n\n    em_preds = logits_em.argmax(dim=1).cpu().numpy()\n    cl_preds = logits_cl.argmax(dim=1).cpu().numpy()\n    emotions = emotion_encoder.inverse_transform(em_preds)\n    clause_types = clause_encoder.inverse_transform(cl_preds)\n\n    edge_index = build_graph(feats).to(device)\n    with torch.no_grad():\n        edge_logits = gat_model(feats, edge_index).cpu()\n    edge_type_pred = (torch.sigmoid(edge_logits) > 0.55).long().numpy()\n    cause_types = type_decoder.inverse_transform(edge_type_pred)\n\n    results = {\n        'clauses': [],\n        'cause_pairs': []\n    }\n    for idx, cl in enumerate(clauses):\n        results['clauses'].append({\n            'text': cl,\n            'emotion': emotions[idx],\n            'clause_type': clause_types[idx]\n        })\n    rows, cols = edge_index.cpu().numpy()\n    for k, (i, j) in enumerate(zip(rows, cols)):\n        results['cause_pairs'].append({\n            'source_clause': i,\n            'target_clause': j,\n            'cause_type': cause_types[k]\n        })\n    return results\n\n\ndef load_artifacts(args, device):\n    tokenizer_emotion = AutoTokenizer.from_pretrained(args.tokenizer_emotion)\n    tokenizer_clause  = AutoTokenizer.from_pretrained(args.tokenizer_clause)\n\n    with open(args.encoder_path, 'rb') as f:\n        encoders = pickle.load(f)\n    emotion_encoder = encoders['emotion']\n    clause_encoder = encoders['clause']\n    type_decoder = encoders['cause_type']\n\n    model_emotion = torch.load(args.emotion_model_path, map_location=device)\n    model_emotion.eval()\n    model_clause = torch.load(args.clause_model_path, map_location=device)\n    model_clause.eval()\n    gat_model = torch.load(args.gat_model_path, map_location=device)\n    gat_model.eval()\n\n    return tokenizer_emotion, tokenizer_clause, model_emotion, model_clause, gat_model, emotion_encoder, clause_encoder, type_decoder\n\n\ndef main():\n    parser = argparse.ArgumentParser(\"Emotion-Cause Inference Pipeline\")\n    parser.add_argument('--input', type=str, required=True, help='/kaggle/working/clean_conversation.json')\n    parser.add_argument('--output', type=str, required=True, help='/kaggle/working/clean_conversation_labelled.json')\n    parser.add_argument('--tokenizer-emotion', type=str, required=True, help='/kaggle/input/tokenizer/tokenizer (1).json')\n    parser.add_argument('--tokenizer-clause', type=str, required=True, help='/kaggle/input/tokenizer/tokenizer.json')\n    parser.add_argument('--encoder-path', type=str, required=True, help='Pickle file with LabelEncoders')\n    parser.add_argument('--emotion-model-path', type=str, required=True, help='Path to emotion classifier .pth')\n    parser.add_argument('--clause-model-path', type=str, required=True, help='Path to clause-type classifier .pth')\n    parser.add_argument('--gat-model-path', type=str, required=True, help='Path to GAT model .pth')\n    parser.add_argument('--spacy-model', type=str, default='en_core_web_sm', help='spaCy model for clause splitting')\n    args = parser.parse_args()\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    nlp = spacy.load(args.spacy_model)\n\n    tokenizer_emotion, tokenizer_clause, model_emotion, model_clause, gat_model, emotion_encoder, clause_encoder, type_decoder = load_artifacts(args, device)\n\n    with open(args.input, 'r', encoding='utf-8') as f:\n        convs = json.load(f)\n\n    all_results = {}\n    for conv_id, turns in convs.items():\n        res = inference_pipeline(\n            turns, tokenizer_emotion, tokenizer_clause,\n            model_emotion, model_clause, gat_model,\n            emotion_encoder, clause_encoder, type_decoder,\n            device, nlp\n        )\n        all_results[conv_id] = res\n\n    with open(args.output, 'w', encoding='utf-8') as f:\n        json.dump(all_results, f, indent=2)\n    print(f\"Results written to {args.output}\")\n\nif __name__ == '__main__':\n    main()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}